{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 - Fire Evacuation Planning for the MI Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helpers.vae import VariationalAutoEncoder\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers.data import get_fire_evac_dataset\n",
    "from helpers.plots import plot_2d_train_test\n",
    "from helpers.plots import plot_2d_fire_evac_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading the dataset and visualizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train, test = get_fire_evac_dataset()\n",
    "plot_2d_train_test(\n",
    "    train, test, xlabel=\"x\", ylabel=\"y\", title=\"FireEvac Dataset\", save_path=\"plots/fire_evac_data.pdf\", alpha=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Training a VAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data & model configuration\n",
    "latent_dim = 2\n",
    "batch_size = 32\n",
    "hidden_size = 64\n",
    "no_epochs = 200\n",
    "verbosity = 1\n",
    "num_channels = 1\n",
    "input_shape = train[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compared to Task 3, we reduce the batch_size because the train set is smaller"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# preprocess data to be in range [0,1]\n",
    "def normalise(data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalises the data such that all data points are in the range [0,1]\n",
    "    Args:\n",
    "        data (ndarray): data to be normalised\n",
    "\n",
    "    Returns: normalised data\n",
    "\n",
    "    \"\"\"\n",
    "    max = data.max()\n",
    "    min = data.min()\n",
    "\n",
    "    data_normalised = (data - min) / (max - min)\n",
    "    return data_normalised\n",
    "\n",
    "def renormalise(data_normalised: np.ndarray, data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    processes normalised data such that the values are similar to the original data\n",
    "    Args:\n",
    "        data_normalised (ndarray): normalised data in range [0,1]\n",
    "        data (ndarray): original data\n",
    "\n",
    "    Returns: data that has similar values than the original data\n",
    "\n",
    "    \"\"\"\n",
    "    max = data.max()\n",
    "    min = data.min()\n",
    "    data_renormalised = data_normalised * (max - min) + min\n",
    "    return data_renormalised\n",
    "\n",
    "train_normalised = normalise(train)\n",
    "test_normalised = normalise(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Even though it is suggested to normalise the data to the interval [-1,1], we receive better results for interval [0,1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vae = VariationalAutoEncoder(input_shape=input_shape, latent_dim=latent_dim, hidden_size=hidden_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyperparameters were tuned and the network was tested for:\n",
    "- different dimensions of the latent space (2-32): latent_dim=2 returned best results\n",
    "- different batch sizes (8-128), starting with a smaller batch size compared to Task 3 because the train set is smaller: batch_size=32 returned best results\n",
    "- different hidden size (64-1024): hidden_size=64 returned best results\n",
    "- different number of Dense layers (2-4): best results for 2 Dense layers\n",
    "- different learning_rates (0.0001-0.001): best results for learning_rate=0.0005"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compile VAE\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"loss\", patience=50)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "vae.compile(optimizer=opt)\n",
    "# Train autoencoder\n",
    "history = vae.fit(train_normalised, train_normalised, epochs=no_epochs, batch_size=batch_size, validation_data=(test_normalised, test_normalised), callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print loss history\n",
    "loss_history = history.history['val_loss']\n",
    "\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"loss curve of ELBO for test set\")\n",
    "plt.xlabel('#iterations')\n",
    "plt.ylabel('-ELBO loss')\n",
    "plt.show()\n",
    "plt.savefig(\"plots/fire_evac_loss.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Plot of the reconstructed test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_2d_fire_evac_set(test, xlabel=\"x\", ylabel=\"y\", title=\"FireEvac Test Set\", save_path=\"plots/fire_evac_test_data.pdf\", alpha=0.5)\n",
    "\n",
    "test_reconstructed = np.empty_like(test_normalised)\n",
    "for i in range(test_normalised.shape[0]):\n",
    "    _, _, z = vae.encoder(test_normalised[i-1].reshape(-1, 2))\n",
    "    test_sample = vae.decoder(z)[0]\n",
    "    test_reconstructed[i-1] = test_sample\n",
    "\n",
    "test_reconstructed = renormalise(test_reconstructed, test)\n",
    "plot_2d_fire_evac_set(test_reconstructed, xlabel=\"x\", ylabel=\"y\", title=\"FireEvac Reconstructed Test Set\", save_path=\"plots/fire_evac_test_data_reconstruction.pdf\", alpha=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Plot of generated samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO\n",
    "# randomly choose input for decoder\n",
    "# decode\n",
    "# plot generated samples with plot fire evac set\n",
    "\n",
    "def generate_samples(num_samples: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Visualises generation of num_samples digits\n",
    "\n",
    "    Args:\n",
    "        num_samples (int): number of samples to be generated\n",
    "\n",
    "    Returns: array of sampled data\n",
    "    \"\"\"\n",
    "    generated_samples = np.empty(shape=(num_samples, 2))\n",
    "    for i in range(num_samples):\n",
    "        z_sample = np.random.normal(size=latent_dim) \n",
    "        out = vae.decoder(np.array([z_sample]))[0]\n",
    "        generated_samples[i] = out\n",
    "    return renormalise(generated_samples, train)\n",
    "\n",
    "generated_samples = generate_samples(1000)\n",
    "\n",
    "plot_2d_fire_evac_set(generated_samples, xlabel=\"x\", ylabel=\"y\", title=\"FireEvac Generated Set\", save_path=\"plots/fire_evac_test_data_generation.pdf\", alpha=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Generate data to estimate the critical number of people for the MI building"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def count_sensitive_area(samples: np.ndarray) -> int:\n",
    "    \"\"\"\n",
    "    counts the number of samples inside the sensitive area [130<x<150, 50<y<70]\n",
    "    Args:\n",
    "        samples (ndarray): array of samples with positions\n",
    "\n",
    "    Returns: number of samples inside the sensitive area\n",
    "\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for sample in samples:\n",
    "        x, y = sample\n",
    "        if x > 130 and x < 150 and y > 50 and y < 70:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "for i in range(950,1100):\n",
    "    generated_samples = generate_samples(i)\n",
    "    count = count_sensitive_area(generated_samples)\n",
    "    if count > 95:\n",
    "        print(\"For \" + str(i) + \" samples, there are \" + str(count) + \" people in the sensitive area\")\n",
    "    if count > 100:\n",
    "        print(\"CRITICAL NUMBER IS REACHED\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The critical number at the main entrance is reached for approximately 1000 samples (then there are more than 100 people in the area [130,150][50,70]). Approximately 10% of all people are located in the sensitive area. If this area should not allow more than 100 people for safety reasons, then a smaller number needs to be chosen because in some cases, the number is exceeded for 900-950 people in the MI building."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bonus:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generation of 100 people in the MI building\n",
    "generated_positions = generate_samples(100)\n",
    "generated_positions = renormalise(generated_positions, train)\n",
    "\n",
    "plot_2d_fire_evac_set(generated_positions, xlabel=\"x\", ylabel=\"y\", title=\"FireEvac Reconstructed Test Set\", save_path=\"plots/fire_evac_test_data_generation_bonus.pdf\", alpha=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d1a0f5ee93e8ea41525e734c1178b150c3383b451469805b56a05295a9fb3ab"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('mlcs': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}